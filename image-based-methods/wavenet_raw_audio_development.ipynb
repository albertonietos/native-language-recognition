{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavenet for raw audio classification\n",
    "Implementation from this [kaggle notebook](https://www.kaggle.com/hanjoonchoe/wavenet-lstm-pytorch-ignite-ver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'C:/native_language/wav/'\n",
    "label_file = \"C:/native_language/lab/ComParE2016_Nativeness.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = pd.read_csv(label_file, sep=\"\\t\")\n",
    "train_files = data_file['file_name'].str.contains('train')\n",
    "train_df = data_file[train_files]\n",
    "dev_files = data_file['file_name'].str.contains('devel')\n",
    "dev_df = data_file[dev_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_audio(file_path):\n",
    "    wav,sr = librosa.load(file_path,sr=None)\n",
    "    \n",
    "    # trim wav (5-10 seconds)\n",
    "    return wav[80000:160000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self, df, base='C:/native_language/wav/', in_col='file_name', out_col='L1'):\n",
    "        self.df = df\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.c2i={}\n",
    "        self.i2c={}\n",
    "        self.categories = sorted(df[out_col].unique())\n",
    "        for i, category in enumerate(self.categories):\n",
    "            self.c2i[category]=i\n",
    "            self.i2c[i]=category\n",
    "\n",
    "        for ind in range(len(df)):\n",
    "            row = df.iloc[ind]\n",
    "            file_path = os.path.join(base,row[in_col])\n",
    "            label = row[out_col]\n",
    "            self.data.append(get_raw_audio(file_path)[np.newaxis,...])\n",
    "            self.labels.append(self.c2i[row[out_col]])\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Data(train_df, base='C:/native_language/wav/',\n",
    "                  in_col='file_name', out_col='L1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = Data(dev_df, base='C:/native_language/wav/',\n",
    "                  in_col='file_name', out_col='L1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8 #16\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(dev_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device=torch.device('cuda:0')\n",
    "else:\n",
    "    device=torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Wavenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, feature_dim, step_dim, bias=True, **kwargs):\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "        self.supports_masking = True\n",
    "\n",
    "        self.bias = bias\n",
    "        self.feature_dim = feature_dim\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "\n",
    "        weight = torch.zeros(feature_dim, 1)\n",
    "        nn.init.kaiming_uniform_(weight)\n",
    "        self.weight = nn.Parameter(weight)\n",
    "\n",
    "        if bias:\n",
    "            self.b = nn.Parameter(torch.zeros(step_dim))\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        feature_dim = self.feature_dim\n",
    "        step_dim = self.step_dim\n",
    "        \n",
    "        eij = torch.mm(\n",
    "            x.contiguous().view(-1, feature_dim),\n",
    "            self.weight\n",
    "        ).view(-1, step_dim)\n",
    "    \n",
    "        if self.bias:\n",
    "            eij = eij + self.b\n",
    "\n",
    "        eij = torch.tanh(eij)\n",
    "        a = torch.exp(eij)\n",
    "\n",
    "        if mask is not None:\n",
    "            a = a * mask\n",
    "\n",
    "        a = a / (torch.sum(a, 1, keepdim=True) + 1e-10)\n",
    "\n",
    "        weighted_input = x * torch.unsqueeze(a, -1)\n",
    "        return torch.sum(weighted_input, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wave_Block(nn.Module):\n",
    "    \n",
    "    def __init__(self,in_channels,out_channels,dilation_rates):\n",
    "        super(Wave_Block,self).__init__()\n",
    "        self.num_rates = dilation_rates\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.filter_convs = nn.ModuleList()\n",
    "        self.gate_convs = nn.ModuleList()\n",
    "        \n",
    "        self.convs.append(nn.Conv1d(in_channels,out_channels,kernel_size=1))\n",
    "        dilation_rates = [2**i for i in range(dilation_rates)]\n",
    "        for dilation_rate in dilation_rates:\n",
    "            self.filter_convs.append(nn.Conv1d(out_channels,out_channels,kernel_size=3,padding=dilation_rate,dilation=dilation_rate))\n",
    "            self.gate_convs.append(nn.Conv1d(out_channels,out_channels,kernel_size=3,padding=dilation_rate,dilation=dilation_rate))\n",
    "            self.convs.append(nn.Conv1d(out_channels,out_channels,kernel_size=1))\n",
    "            \n",
    "    def forward(self,x):\n",
    "        x = self.convs[0](x)\n",
    "        res = x\n",
    "        for i in range(self.num_rates):\n",
    "            x = torch.tanh(self.filter_convs[i](x))*torch.sigmoid(self.gate_convs[i](x))\n",
    "            x = self.convs[i+1](x)\n",
    "            x += res\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wave_LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        in_channels = 80000 #150000 result of number of frames\n",
    "        \n",
    "        self.wave_block1 = Wave_Block(1,16,8)\n",
    "        self.wave_block2 = Wave_Block(16,32,5)\n",
    "        self.wave_block3 = Wave_Block(32,64,3)\n",
    "        self.avgpool1d = nn.AvgPool1d(10)\n",
    "        \n",
    "        self.LSTM = nn.GRU(input_size=in_channels//10**3, hidden_size=in_channels//10**3,\n",
    "                           num_layers=64, batch_first=True, bidirectional=True)\n",
    "        #self.attention = Attention(300,64)\n",
    "        self.attention = Attention(160,64) # result of in_channels / 500\n",
    "        \n",
    "        #self.conv1 = nn.Linear(300,128)\n",
    "        self.conv1 = nn.Linear(160,128) # it has to match the output from attention\n",
    "        #self.conv2 = nn.Linear(128,1)\n",
    "        self.conv2 = nn.Linear(128,11) # needs to have the same number of outputs as categories\n",
    "            \n",
    "    def forward(self,x):\n",
    "        x = self.wave_block1(x)\n",
    "        #shrinking\n",
    "        x = self.avgpool1d(x)\n",
    "        x = self.wave_block2(x)\n",
    "        #shrinking\n",
    "        x = self.avgpool1d(x)\n",
    "        x = self.wave_block3(x)\n",
    "        #shrinking\n",
    "        x = self.avgpool1d(x)\n",
    "        #print(\"Before LSTM\", x.size())\n",
    "        x,_ = self.LSTM(x)\n",
    "        #print(\"x.size() after LSTM\", x.size())\n",
    "        x = self.attention(x)\n",
    "        x = F.dropout(x,0.2)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        #print(\"FINAL OUTPUT\", x.size())\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBefore LSTM torch.Size([2, 64, 150])\\nAfter LSTM torch.Size([2, 64, 300])\\nfeature_dim 300 step_dim 64\\nAfter attention torch.Size([2, 300])\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Before LSTM torch.Size([2, 64, 150])\n",
    "After LSTM torch.Size([2, 64, 300])\n",
    "feature_dim 300 step_dim 64\n",
    "After attention torch.Size([2, 300])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Wave_LSTM().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "learning_rate = 2e-5\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "epochs = 30\n",
    "train_losses = []\n",
    "valid_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, train_loader, valid_loader, epochs, optimizer, train_losses, valid_losses, change_lr=None):\n",
    "    for epoch in range(1,epochs+1):\n",
    "        model.train()\n",
    "        batch_losses=[]\n",
    "        if change_lr:\n",
    "            optimizer = change_lr(optimizer, epoch)\n",
    "        for i, data in enumerate(train_loader):\n",
    "            x, y = data\n",
    "            optimizer.zero_grad()\n",
    "            x = x.to(device, dtype=torch.float32)\n",
    "            y = y.to(device, dtype=torch.long)\n",
    "            y_hat = model(x)\n",
    "            \n",
    "            loss = loss_fn(y_hat, y)\n",
    "            loss.backward()\n",
    "            batch_losses.append(loss.item())\n",
    "            optimizer.step()\n",
    "        train_losses.append(batch_losses)\n",
    "        print(f'Epoch - {epoch} Train-Loss : {np.mean(train_losses[-1]):.3f}')\n",
    "        model.eval()\n",
    "        batch_losses=[]\n",
    "        trace_y = []\n",
    "        trace_yhat = []\n",
    "        for i, data in enumerate(valid_loader):\n",
    "            x, y = data\n",
    "            x = x.to(device, dtype=torch.float32)\n",
    "            y = y.to(device, dtype=torch.long)\n",
    "            y_hat = model(x)\n",
    "            loss = loss_fn(y_hat, y)\n",
    "            trace_y.append(y.cpu().detach().numpy())\n",
    "            trace_yhat.append(y_hat.cpu().detach().numpy())      \n",
    "            batch_losses.append(loss.item())\n",
    "        valid_losses.append(batch_losses)\n",
    "        trace_y = np.concatenate(trace_y)\n",
    "        trace_yhat = np.concatenate(trace_yhat)\n",
    "        accuracy = np.mean(trace_yhat.argmax(axis=1)==trace_y)\n",
    "        print(f'Epoch - {epoch} Valid-Loss : {np.mean(valid_losses[-1]):.3f} Valid-Accuracy : {accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setlr(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_decay(optimizer, epoch):\n",
    "    if epoch % 5==0:\n",
    "        new_lr = learning_rate / (10**(epoch//20))\n",
    "        optimizer = setlr(optimizer, new_lr)\n",
    "        print(f'Changed learning rate to {new_lr}')\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBefore LSTM torch.Size([2, 64, 150])\\nAfter LSTM torch.Size([2, 64, 300])\\nfeature_dim 300 step_dim 64\\nAfter attention torch.Size([2, 300])\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Before LSTM torch.Size([2, 64, 150])\n",
    "After LSTM torch.Size([2, 64, 300])\n",
    "feature_dim 300 step_dim 64\n",
    "After attention torch.Size([2, 300])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 1 Train-Loss : 2.401\n",
      "Epoch - 1 Valid-Loss : 2.400 Valid-Accuracy : 0.089\n",
      "Epoch - 2 Train-Loss : 2.399\n",
      "Epoch - 2 Valid-Loss : 2.398 Valid-Accuracy : 0.101\n",
      "Epoch - 3 Train-Loss : 2.400\n",
      "Epoch - 3 Valid-Loss : 2.399 Valid-Accuracy : 0.088\n",
      "Epoch - 4 Train-Loss : 2.399\n",
      "Epoch - 4 Valid-Loss : 2.399 Valid-Accuracy : 0.083\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'setlr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-2cbcb9950e74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_decay\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-16-dddadc8b42ad>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, loss_fn, train_loader, valid_loader, epochs, optimizer, train_losses, valid_losses, change_lr)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mbatch_losses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mchange_lr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchange_lr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-74a7415d9a56>\u001b[0m in \u001b[0;36mlr_decay\u001b[1;34m(optimizer, epoch)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mnew_lr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msetlr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_lr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Changed learning rate to {new_lr}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'setlr' is not defined"
     ]
    }
   ],
   "source": [
    "train(model, loss_fn, train_loader, valid_loader, epochs, optimizer, train_losses, valid_losses, lr_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
